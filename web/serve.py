#!/usr/bin/env python3
"""
Simple HTTP server for wherewasi HTMX demo
Serves static files and simulates the context API
"""

import http.server
import socketserver
import json
import os
from urllib.parse import urlparse, parse_qs

class WhereWasIHandler(http.server.SimpleHTTPRequestHandler):
    def do_GET(self):
        # Serve index.html for root request
        if self.path == '/':
            self.path = '/index.html'
        return super().do_GET()

    def do_POST(self):
        if self.path == '/api/pull-context':
            self.send_context_response()
        else:
            self.send_error(404, "Not Found")

    def send_context_response(self):
        # Simulate wherewasi context generation
        context_data = """ğŸª‚ WHEREWASI CONTEXT - Development Session
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ PROJECT: wherewasi (AI context generation CLI)
ğŸ“… TIMEFRAME: Last 7 days
âš¡ ACTIVE SESSION: HTMX demo development detected

ğŸ¯ PROJECT SUMMARY:
Local-first context generation CLI for AI collaboration. Working MVP with
ecosystem tracking, ripcord-style emergency context deployment, and cross-
project intelligence gathering.

ğŸ“ RECENT ACTIVITY:
â€¢ HTMX landing page created with ripcord theme
â€¢ Framework experimentation: Fresh/Deno for osmotic
â€¢ SlopSquid rebrand to CLI tool with tentacles concept
â€¢ Domain portfolio strategy for framework testing

ğŸ” KEY FILES:
main.go â†’ Core CLI with SQLite context storage
web/index.html â†’ HTMX demo with parachute animations
README.md â†’ Usage examples and ecosystem integration
internal/database/ â†’ Cross-project tracking logic

ğŸ’¬ RECENT CONVERSATIONS:
AI_SESSION.md:156-234 â†’ Context generation architecture
cursor_htmx_demo.md:45-67 â†’ Interactive ripcord implementation

ğŸš€ NEXT PRIORITIES:
â€¢ Connect demo to real wherewasi CLI instance
â€¢ Add miqro.dev Astro site development
â€¢ Integrate context sharing across QRY ecosystem

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš¡ Context ready for AI collaboration â†’ Copied to clipboard"""

        # Send HTML response for HTMX
        self.send_response(200)
        self.send_header('Content-type', 'text/html')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()

        # Return pre-formatted context for display
        response_html = f'<pre style="white-space: pre-wrap;">{context_data}</pre>'
        self.wfile.write(response_html.encode('utf-8'))

    def log_message(self, format, *args):
        # Custom logging
        print(f"ğŸª‚ {self.address_string()} - {format % args}")

def run_server(port=8080):
    # Change to the web directory
    web_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(web_dir)

    with socketserver.TCPServer(("", port), WhereWasIHandler) as httpd:
        print(f"ğŸª‚ WhereWasI HTMX Demo Server")
        print(f"ğŸ“¡ Serving at http://localhost:{port}")
        print(f"ğŸ“ Directory: {web_dir}")
        print(f"ğŸ¯ Pull the ripcord to test context generation!")
        print("â”" * 50)

        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            print("\nğŸª‚ Ripcord pulled! Server landing safely...")

if __name__ == "__main__":
    run_server()
